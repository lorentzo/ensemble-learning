{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Towards Gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOOSTING:\n",
    "* The idea of boosting came out of the idea of whether a weak learner can be modified to become better.\n",
    "* general ensembe method\n",
    "* adding models until prefect prediction on data is made\n",
    "* AdaBoost first successful algorithm. Used for binary classicication\n",
    "* modern boosing methods build on AdaBoost - e.g. gradient boosting machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADABOOST:\n",
    "* boost performace on decision trees for binary classification\n",
    "* originally AdaBoost.M1, nowdays discrete AdaBoost (because it is used for classification)\n",
    "* it can be used to boost any machine learning algorithm. Best works with weak learners (weak learner - accuracy just above random chance)\n",
    "* mostly used on decision tree with one level (contain only one decision for classification) - called decision stumps\n",
    "* each example in training set is weighted. Initial weight: uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING ONE MODEL\n",
    "* weak classifier (stump) is prepared on training data using weighted samples\n",
    "* only binary classification problems are supported. Every stump has -1 or +1 output\n",
    "* missclasification rate for trained model: err = (correct - N) / N. Where N is total number of train examples, correct is total number of correct predictions\n",
    "* for weighted examples: err = sum(w(i) * terror(i)) / sum(w). Where w(i) is weight for train example and terror is 0 or 1 depending on missclassification\n",
    "* weights for one example are updated: w := w * exp(stage * terror). Where stage = ln((1-err)/err) and terror is 0 or 1 depending on missclassification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADABOOST ENSEMBLE\n",
    "* weak learners are added sequentially until no imporvement on data or max learners are added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADABOOST PREDICTION\n",
    "* weighted average of weak classifiers\n",
    "* for new instance each classifier calculates prediction. Values are weighted by stage value. Prediction is sum of weighted predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA\n",
    "* high quality (no wrong labelling)\n",
    "* no outliers\n",
    "* no noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERALIZATION OF ADABOOST: GRADIENT BOOSTING\n",
    "* statistical framework: ARCing algorithms (Adaptive Reweighting and Combining). Each step: weighted minimization and recomputation of classifiers and weights\n",
    "* framework is now called Gradient Boosting machines (gradient boosting gradient tree boosting)\n",
    "* here boosting is numerical optimization where objective is to minimize the loss by adding weak learners using procedure like gradient descend\n",
    "* stage-wise additive model: new model is added while other are fixed\n",
    "* this allowed use of different loss functions, so regression, multiclass are supported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How gradient boosting works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOSS FUNCTION TO BE OPTIMIZED\n",
    "* depend on problem (classification (binary, multi), regression)\n",
    "* classification: logarithmic loss, cross entropy\n",
    "* regression: SE\n",
    "* any differentiable loss function can be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEAK LEARNERS\n",
    "* decision trees are used; regression tree (real valued output)\n",
    "* tree is constructed greedy: best split depends on scores (Gini) or loss\n",
    "* beside stumps, 4-8 level trees can be used\n",
    "* constrain learners: max no of layers, nodes, splits, leaf nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADDITIVE MODE\n",
    "* new trees are added one at time while existing ones are unchanged. New models correct residual errors of all previous trees\n",
    "* gradient descend is used to minimize the loss when adding trees. After calculating the loss just like in gradient descend we add tree (change parameter) to reduce loss. Here parameters are new trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST: implementation of gradient boosting\n",
    "* eXtreme Gradient Boosting. In addition to variations of method, interest was speed of algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('pima-indians-diabetes.data.csv', delimiter=\",\")\n",
    "\n",
    "# split into X and y\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "* XGBoost provide wrapper class for creating classifier or regressior object for scikit-learn framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7795275590551181\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = [round(x) for x in y_pred]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Monitor performance and Early stopping\n",
    "* XGBoost model can evaluate and report performance on test set DURING training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.259843\n",
      "[1]\tvalidation_0-error:0.26378\n",
      "[2]\tvalidation_0-error:0.26378\n",
      "[3]\tvalidation_0-error:0.255906\n",
      "[4]\tvalidation_0-error:0.255906\n",
      "[5]\tvalidation_0-error:0.26378\n",
      "[6]\tvalidation_0-error:0.23622\n",
      "[7]\tvalidation_0-error:0.255906\n",
      "[8]\tvalidation_0-error:0.248031\n",
      "[9]\tvalidation_0-error:0.248031\n",
      "[10]\tvalidation_0-error:0.248031\n",
      "[11]\tvalidation_0-error:0.232283\n",
      "[12]\tvalidation_0-error:0.228346\n",
      "[13]\tvalidation_0-error:0.228346\n",
      "[14]\tvalidation_0-error:0.228346\n",
      "[15]\tvalidation_0-error:0.228346\n",
      "[16]\tvalidation_0-error:0.228346\n",
      "[17]\tvalidation_0-error:0.228346\n",
      "[18]\tvalidation_0-error:0.224409\n",
      "[19]\tvalidation_0-error:0.232283\n",
      "[20]\tvalidation_0-error:0.232283\n",
      "[21]\tvalidation_0-error:0.23622\n",
      "[22]\tvalidation_0-error:0.23622\n",
      "[23]\tvalidation_0-error:0.232283\n",
      "[24]\tvalidation_0-error:0.228346\n",
      "[25]\tvalidation_0-error:0.228346\n",
      "[26]\tvalidation_0-error:0.224409\n",
      "[27]\tvalidation_0-error:0.224409\n",
      "[28]\tvalidation_0-error:0.228346\n",
      "[29]\tvalidation_0-error:0.232283\n",
      "[30]\tvalidation_0-error:0.228346\n",
      "[31]\tvalidation_0-error:0.224409\n",
      "[32]\tvalidation_0-error:0.224409\n",
      "[33]\tvalidation_0-error:0.228346\n",
      "[34]\tvalidation_0-error:0.228346\n",
      "[35]\tvalidation_0-error:0.224409\n",
      "[36]\tvalidation_0-error:0.228346\n",
      "[37]\tvalidation_0-error:0.224409\n",
      "[38]\tvalidation_0-error:0.216535\n",
      "[39]\tvalidation_0-error:0.220472\n",
      "[40]\tvalidation_0-error:0.216535\n",
      "[41]\tvalidation_0-error:0.216535\n",
      "[42]\tvalidation_0-error:0.216535\n",
      "[43]\tvalidation_0-error:0.216535\n",
      "[44]\tvalidation_0-error:0.212598\n",
      "[45]\tvalidation_0-error:0.224409\n",
      "[46]\tvalidation_0-error:0.224409\n",
      "[47]\tvalidation_0-error:0.220472\n",
      "[48]\tvalidation_0-error:0.224409\n",
      "[49]\tvalidation_0-error:0.232283\n",
      "[50]\tvalidation_0-error:0.228346\n",
      "[51]\tvalidation_0-error:0.224409\n",
      "[52]\tvalidation_0-error:0.224409\n",
      "[53]\tvalidation_0-error:0.232283\n",
      "[54]\tvalidation_0-error:0.228346\n",
      "[55]\tvalidation_0-error:0.228346\n",
      "[56]\tvalidation_0-error:0.224409\n",
      "[57]\tvalidation_0-error:0.224409\n",
      "[58]\tvalidation_0-error:0.224409\n",
      "[59]\tvalidation_0-error:0.224409\n",
      "[60]\tvalidation_0-error:0.224409\n",
      "[61]\tvalidation_0-error:0.224409\n",
      "[62]\tvalidation_0-error:0.224409\n",
      "[63]\tvalidation_0-error:0.224409\n",
      "[64]\tvalidation_0-error:0.224409\n",
      "[65]\tvalidation_0-error:0.224409\n",
      "[66]\tvalidation_0-error:0.220472\n",
      "[67]\tvalidation_0-error:0.216535\n",
      "[68]\tvalidation_0-error:0.216535\n",
      "[69]\tvalidation_0-error:0.216535\n",
      "[70]\tvalidation_0-error:0.216535\n",
      "[71]\tvalidation_0-error:0.216535\n",
      "[72]\tvalidation_0-error:0.216535\n",
      "[73]\tvalidation_0-error:0.216535\n",
      "[74]\tvalidation_0-error:0.216535\n",
      "[75]\tvalidation_0-error:0.216535\n",
      "[76]\tvalidation_0-error:0.216535\n",
      "[77]\tvalidation_0-error:0.216535\n",
      "[78]\tvalidation_0-error:0.216535\n",
      "[79]\tvalidation_0-error:0.212598\n",
      "[80]\tvalidation_0-error:0.212598\n",
      "[81]\tvalidation_0-error:0.212598\n",
      "[82]\tvalidation_0-error:0.212598\n",
      "[83]\tvalidation_0-error:0.212598\n",
      "[84]\tvalidation_0-error:0.208661\n",
      "[85]\tvalidation_0-error:0.204724\n",
      "[86]\tvalidation_0-error:0.212598\n",
      "[87]\tvalidation_0-error:0.212598\n",
      "[88]\tvalidation_0-error:0.212598\n",
      "[89]\tvalidation_0-error:0.204724\n",
      "[90]\tvalidation_0-error:0.208661\n",
      "[91]\tvalidation_0-error:0.208661\n",
      "[92]\tvalidation_0-error:0.208661\n",
      "[93]\tvalidation_0-error:0.208661\n",
      "[94]\tvalidation_0-error:0.208661\n",
      "[95]\tvalidation_0-error:0.212598\n",
      "[96]\tvalidation_0-error:0.204724\n",
      "[97]\tvalidation_0-error:0.212598\n",
      "[98]\tvalidation_0-error:0.216535\n",
      "[99]\tvalidation_0-error:0.220472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Before training we need to specify: test set and evaluation metric\n",
    "eval_set = [(X_test, y_test)] \n",
    "\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          eval_metric='error', # binary classification error\n",
    "          eval_set=eval_set, \n",
    "          verbose=True) # using test set during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to stop training once evaluation error is minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.660186\n",
      "Will train until validation_0-logloss hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-logloss:0.634854\n",
      "[2]\tvalidation_0-logloss:0.612239\n",
      "[3]\tvalidation_0-logloss:0.593118\n",
      "[4]\tvalidation_0-logloss:0.578303\n",
      "[5]\tvalidation_0-logloss:0.564942\n",
      "[6]\tvalidation_0-logloss:0.555113\n",
      "[7]\tvalidation_0-logloss:0.54499\n",
      "[8]\tvalidation_0-logloss:0.539151\n",
      "[9]\tvalidation_0-logloss:0.531819\n",
      "[10]\tvalidation_0-logloss:0.526065\n",
      "[11]\tvalidation_0-logloss:0.51977\n",
      "[12]\tvalidation_0-logloss:0.514979\n",
      "[13]\tvalidation_0-logloss:0.50927\n",
      "[14]\tvalidation_0-logloss:0.506086\n",
      "[15]\tvalidation_0-logloss:0.503565\n",
      "[16]\tvalidation_0-logloss:0.503591\n",
      "[17]\tvalidation_0-logloss:0.500805\n",
      "[18]\tvalidation_0-logloss:0.497605\n",
      "[19]\tvalidation_0-logloss:0.495328\n",
      "[20]\tvalidation_0-logloss:0.494777\n",
      "[21]\tvalidation_0-logloss:0.494274\n",
      "[22]\tvalidation_0-logloss:0.493333\n",
      "[23]\tvalidation_0-logloss:0.492211\n",
      "[24]\tvalidation_0-logloss:0.491936\n",
      "[25]\tvalidation_0-logloss:0.490578\n",
      "[26]\tvalidation_0-logloss:0.490895\n",
      "[27]\tvalidation_0-logloss:0.490646\n",
      "[28]\tvalidation_0-logloss:0.491911\n",
      "[29]\tvalidation_0-logloss:0.491407\n",
      "[30]\tvalidation_0-logloss:0.488828\n",
      "[31]\tvalidation_0-logloss:0.487867\n",
      "[32]\tvalidation_0-logloss:0.487297\n",
      "[33]\tvalidation_0-logloss:0.487562\n",
      "[34]\tvalidation_0-logloss:0.487788\n",
      "[35]\tvalidation_0-logloss:0.487962\n",
      "[36]\tvalidation_0-logloss:0.488218\n",
      "[37]\tvalidation_0-logloss:0.489582\n",
      "[38]\tvalidation_0-logloss:0.489334\n",
      "[39]\tvalidation_0-logloss:0.490969\n",
      "[40]\tvalidation_0-logloss:0.48978\n",
      "[41]\tvalidation_0-logloss:0.490704\n",
      "[42]\tvalidation_0-logloss:0.492369\n",
      "Stopping. Best iteration:\n",
      "[32]\tvalidation_0-logloss:0.487297\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          early_stopping_rounds=10, # early stopping\n",
    "          eval_metric='logloss',\n",
    "          eval_set=eval_set, \n",
    "          verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.56%\n"
     ]
    }
   ],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature importance with XGBoost\n",
    "* benefit of using trees as classifiers is that we can automatically estimate importance of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05090909 0.22909091 0.06909091 0.07636364 0.04727273 0.17818181\n",
      " 0.12       0.22909091]\n"
     ]
    }
   ],
   "source": [
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_importance(model)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure gradient boosting\n",
    "* Learning rate (shrinkage) should be lower then 0.1 (smaller values require more trees)\n",
    "* depth of trees: 2-8 (deep trees are not better)\n",
    "* row sampling: 30% - 80% of training set (100% no sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General configuration strategy:\n",
    "1. run default config and use learning curves on train and validation set\n",
    "2. if overfit: decrease learning rate and increase number of trees\n",
    "3. if underfit: increase learning rate and decrease number of trees\n",
    "* Additional: set number of trees to value (e.g. 100 or 1000) and find best learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. XGBoost Hyperparameter Tuning\n",
    "* we will use grid search: number of trees and tree depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [50, 100, 150, 200]\n",
    "max_depth = [2, 4, 6, 8]\n",
    "param_grid = dict(max_depth=max_depth, n_estimators=n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate each combination of parameters using 10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:    5.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'max_depth': 2, 'n_estimators': 50}, {'max_depth': 2, 'n_estimators': 100}, {'max_depth': 2, 'n_estimators': 150}, {'max_depth': 2, 'n_estimators': 200}, {'max_depth': 4, 'n_estimators': 50}, {'max_depth': 4, 'n_estimators': 100}, {'max_depth': 4, 'n_estimators': 150}, {'max_depth': 4, 'n_estimators': 200}, {'max_depth': 6, 'n_estimators': 50}, {'max_depth': 6, 'n_estimators': 100}, {'max_depth': 6, 'n_estimators': 150}, {'max_depth': 6, 'n_estimators': 200}, {'max_depth': 8, 'n_estimators': 50}, {'max_depth': 8, 'n_estimators': 100}, {'max_depth': 8, 'n_estimators': 150}, {'max_depth': 8, 'n_estimators': 200}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:    9.0s finished\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, \n",
    "                        shuffle=True, \n",
    "                        random_state=7)\n",
    "\n",
    "grid_search = GridSearchCV(model, \n",
    "                           param_grid, \n",
    "                           scoring='neg_log_loss', \n",
    "                           n_jobs=-1, \n",
    "                           cv=kfold, \n",
    "                           verbose=True)\n",
    "\n",
    "result = grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.47896611971373204 {'max_depth': 2, 'n_estimators': 50} 0.037297324488304674\n",
      "-0.47436992467191885 {'max_depth': 2, 'n_estimators': 100} 0.04089868717959626\n",
      "-0.47833176125580695 {'max_depth': 2, 'n_estimators': 150} 0.046846180340347106\n",
      "-0.4877377669267844 {'max_depth': 2, 'n_estimators': 200} 0.0518821744193956\n",
      "-0.4918316121159781 {'max_depth': 4, 'n_estimators': 50} 0.05475397509994463\n",
      "-0.5087815375012118 {'max_depth': 4, 'n_estimators': 100} 0.06035662696209898\n",
      "-0.5346456203333219 {'max_depth': 4, 'n_estimators': 150} 0.07157062565333416\n",
      "-0.5652491507248291 {'max_depth': 4, 'n_estimators': 200} 0.07967163513615395\n",
      "-0.5141908989141181 {'max_depth': 6, 'n_estimators': 50} 0.06392398952701202\n",
      "-0.5520134320093651 {'max_depth': 6, 'n_estimators': 100} 0.07491469087936664\n",
      "-0.5941364662188183 {'max_depth': 6, 'n_estimators': 150} 0.07858724481204003\n",
      "-0.6405230254060067 {'max_depth': 6, 'n_estimators': 200} 0.08881014093049755\n",
      "-0.5402152439710335 {'max_depth': 8, 'n_estimators': 50} 0.07977897345227729\n",
      "-0.5992183939822553 {'max_depth': 8, 'n_estimators': 100} 0.09148149305700966\n",
      "-0.6479166117275099 {'max_depth': 8, 'n_estimators': 150} 0.10389971228948855\n",
      "-0.6862910813387089 {'max_depth': 8, 'n_estimators': 200} 0.11529136442472528\n"
     ]
    }
   ],
   "source": [
    "params = result.cv_results_['params']\n",
    "means = result.cv_results_['mean_test_score']\n",
    "stds = result.cv_results_['std_test_score']\n",
    "for mean, param, std in zip(means, params, stds):\n",
    "    print(mean, param, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
